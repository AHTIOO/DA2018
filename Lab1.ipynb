{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный ноутбук содержит пример выполнения первой лабораторной работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import pickle\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# GLOBAL PARAMETERS\n",
    "# Data\n",
    "cifar_file_name = \"cifar-10-python.tar.gz\"\n",
    "url = 'https://www.cs.toronto.edu/~kriz/'\n",
    "data_root = '.' # Change me to store data elsewhere\n",
    "cifar_dir_name = \"cifar-10-batches-py\"  # where cifar data is stored locally\n",
    "# Learning\n",
    "alpha = 0.5  # learning rate\n",
    "num_epochs = 500  # number of learning epochs \n",
    "batch_size = 1000  # mini-batch size for gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функции для загрузки данных с удаленного сервера и разархивации их в локальный каталог."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File  .\\cifar-10-python.tar.gz  size :  170498071  bytes.\n"
     ]
    }
   ],
   "source": [
    "def maybe_download():\n",
    "    \"\"\"Download the file if it does not exist.\"\"\"\n",
    "\n",
    "    dest_file_name = os.path.join(data_root, cifar_file_name)\n",
    "\n",
    "    if not os.path.exists(dest_file_name):\n",
    "        urlretrieve(url + cifar_file_name, dest_file_name)\n",
    "\n",
    "    statinfo = os.stat(dest_file_name)\n",
    "    print(\"File \", dest_file_name, \" size : \", statinfo.st_size, \" bytes.\")\n",
    "\n",
    "    return dest_file_name\n",
    "\n",
    "\n",
    "def maybe_extract(file_name):\n",
    "    \"\"\"Extract compressed file if is was not uncomressed before.\"\"\"\n",
    "\n",
    "    tar = tarfile.open(file_name)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "\n",
    "    dest_dir_name = os.path.join(data_root, cifar_dir_name)\n",
    "    if not os.path.exists(dest_dir_name):\n",
    "        raise Exception(\"No data directory. Check that archive with data exists, not corrupted and contains \",\n",
    "                        cifar_dir_name, \" inside.\")\n",
    "\n",
    "    return dest_dir_name\n",
    "\n",
    "\n",
    "data_file_name = maybe_download()\n",
    "data_dir_name = maybe_extract(data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных.\n",
    "\n",
    "После разархивации получим набор двоичных фалов, в которых хранятся данные CIFAR. \n",
    "\n",
    "Тренировочная выборка разбита на 5 файлов (data_batch_1, ..., data_batch_5). Прочтем все эти файлы и объединим данные из них в один массив. Затем загрузим тестовую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  .\\cifar-10-batches-py/data_batch_1 ...\n",
      "Done.\n",
      "Loading  .\\cifar-10-batches-py/data_batch_2 ...\n",
      "Done.\n",
      "Loading  .\\cifar-10-batches-py/data_batch_3 ...\n",
      "Done.\n",
      "Loading  .\\cifar-10-batches-py/data_batch_4 ...\n",
      "Done.\n",
      "Loading  .\\cifar-10-batches-py/data_batch_5 ...\n",
      "Done.\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# load train and test data\n",
    "train_batches = [\"data_batch_1\",\n",
    "                 \"data_batch_2\",\n",
    "                 \"data_batch_3\",\n",
    "                 \"data_batch_4\",\n",
    "                 \"data_batch_5\",\n",
    "                ]\n",
    "\n",
    "\n",
    "train_labels = []\n",
    "train_data = []\n",
    "for train_batch in train_batches:\n",
    "    path_to_batch = data_dir_name + \"/\" + train_batch\n",
    "    print(\"Loading \", path_to_batch, \"...\")\n",
    "    batch = pickle.load(open(path_to_batch, \"rb\"), encoding=\"bytes\")\n",
    "    # batch is a dictionary, dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
    "    # let's store data and labels for all batches in a separate arrays\n",
    "    train_labels.extend(batch[b\"labels\"])\n",
    "    train_data.extend(batch[b\"data\"])\n",
    "    print(\"Done.\")\n",
    "    \n",
    "# also load titles for labels\n",
    "raw = pickle.load(open(data_dir_name + \"/batches.meta\", \"rb\"))\n",
    "class_names = [x for x in raw[\"label_names\"]]\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f3c34c42e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's have a look at a sample image\n",
    "sample_no = 0\n",
    "sample_data = train_data[sample_no]\n",
    "\n",
    "sample_image = np.reshape(sample_data, [3, 32, 32])\n",
    "sample_image = np.swapaxes(sample_image, 0, 2)\n",
    "sample_image = np.transpose(sample_image, [1, 0, 2])\n",
    "\n",
    "matplotlib.pyplot.imshow(sample_image)\n",
    "print(class_names[train_labels[sample_no]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, m, v):\n",
    "    if not m.any():\n",
    "        m = np.mean(X, axis=0)\n",
    "    if not v.any():\n",
    "        v = np.var(X, axis=0)\n",
    "    X = (X - m) / v\n",
    "    return X, m, v\n",
    "\n",
    "\n",
    "def preprocess_labels(y, num_classes):\n",
    "    y_gt = np.zeros((len(y), num_classes))\n",
    "    for i in range(0, len(y)):\n",
    "        y_gt[i, y[i]] = 1\n",
    "    return y_gt\n",
    "\n",
    "\n",
    "def h(theta, X):\n",
    "    return 1.0 / (1 + np.exp(-np.dot(X, theta)))\n",
    "\n",
    "\n",
    "def loss(y_gt, y_pred):\n",
    "    cross_entropy_error = 0.0\n",
    "    for i in range(0, len(y_gt)):\n",
    "        for j in range(0, len(y_gt[i])):\n",
    "            cross_entropy_error -= (y_gt[i][j] * np.log(y_pred[i][j]) + (1 - y_gt[i][j]) * np.log(1 - y_pred[i][j]))\n",
    "    return cross_entropy_error / len(y_gt)\n",
    "\n",
    "\n",
    "def forward(theta_mat, X):\n",
    "    probs = np.array([h(theta_mat[:, i], X) for i in range(0, theta_mat.shape[1])])\n",
    "    return probs.transpose()\n",
    "\n",
    "\n",
    "def derivative(X, y_gt, y_pred):\n",
    "    \"\"\"Derivative of cross-entropy loss over parameters of one logistic classifier.\"\"\"\n",
    "    return np.dot(y_pred - y_gt, X) / len(y_gt)\n",
    "\n",
    "def backward(X, y_gt, theta):\n",
    "    num_features = X.shape[1]\n",
    "    num_classes = y_gt.shape[1]\n",
    "    d_theta = np.zeros([num_features, num_classes])\n",
    "    y_pred = forward(theta, X)\n",
    "    for class_no in range(0, num_classes):\n",
    "        d_theta[:, class_no] = derivative(X, y_gt[:, class_no], y_pred[:, class_no])\n",
    "    return d_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape :  (50000, 3072)\n",
      "Labels shape :  (50000,)\n",
      "Initial loss : 7.86819617587\n",
      "Epoch 0/500 ...........\n",
      "Loss : 7.51806671763  Train accuracy :  11.505  Validation accuracy :  11.61\n",
      "Epoch 1/500 ...........\n",
      "Loss : 7.37234761403  Train accuracy :  12.7175  Validation accuracy :  12.65\n",
      "Epoch 2/500 ...........\n",
      "Loss : 7.29077459673  Train accuracy :  13.7275  Validation accuracy :  13.58\n",
      "Epoch 3/500 ...........\n",
      "Loss : 7.23550456451  Train accuracy :  14.7  Validation accuracy :  14.54\n",
      "Epoch 4/500 ...........\n",
      "Loss : 7.19446975983  Train accuracy :  15.67  Validation accuracy :  15.58\n",
      "Epoch 5/500 ...........\n",
      "Loss : 7.16229564872  Train accuracy :  16.52  Validation accuracy :  16.4\n",
      "Epoch 6/500 ...........\n",
      "Loss : 7.13620079394  Train accuracy :  17.25  Validation accuracy :  17.46\n",
      "Epoch 7/500 ...........\n",
      "Loss : 7.11448333236  Train accuracy :  17.895  Validation accuracy :  18.13\n",
      "Epoch 8/500 ...........\n",
      "Loss : 7.09602081629  Train accuracy :  18.56  Validation accuracy :  18.94\n",
      "Epoch 9/500 ...........\n",
      "Loss : 7.08005062865  Train accuracy :  19.12  Validation accuracy :  19.47\n",
      "Epoch 10/500 ...........\n",
      "Loss : 7.06607314673  Train accuracy :  19.65  Validation accuracy :  20.0\n",
      "Epoch 11/500 ...........\n",
      "Loss : 7.05369293582  Train accuracy :  20.0975  Validation accuracy :  20.45\n",
      "Epoch 12/500 ...........\n",
      "Loss : 7.04262080147  Train accuracy :  20.5875  Validation accuracy :  20.99\n",
      "Epoch 13/500 ...........\n",
      "Loss : 7.03262607229  Train accuracy :  21.0825  Validation accuracy :  21.41\n",
      "Epoch 14/500 ...........\n",
      "Loss : 7.02353302513  Train accuracy :  21.475  Validation accuracy :  21.75\n",
      "Epoch 15/500 ...........\n",
      "Loss : 7.01520913145  Train accuracy :  21.8525  Validation accuracy :  22.12\n",
      "Epoch 16/500 ...........\n",
      "Loss : 7.00754940392  Train accuracy :  22.275  Validation accuracy :  22.44\n",
      "Epoch 17/500 ...........\n",
      "Loss : 7.00044523891  Train accuracy :  22.5625  Validation accuracy :  22.68\n",
      "Epoch 18/500 ...........\n",
      "Loss : 6.99384960288  Train accuracy :  22.8  Validation accuracy :  22.83\n",
      "Epoch 19/500 ...........\n",
      "Loss : 6.98766061604  Train accuracy :  23.065  Validation accuracy :  23.07\n",
      "Epoch 20/500 ...........\n",
      "Loss : 6.98186311303  Train accuracy :  23.2875  Validation accuracy :  23.43\n",
      "Epoch 21/500 ...........\n",
      "Loss : 6.9764041117  Train accuracy :  23.5225  Validation accuracy :  23.7\n",
      "Epoch 22/500 ...........\n",
      "Loss : 6.97124497806  Train accuracy :  23.775  Validation accuracy :  23.9\n",
      "Epoch 23/500 ...........\n",
      "Loss : 6.96636078724  Train accuracy :  23.98  Validation accuracy :  24.15\n",
      "Epoch 24/500 ...........\n",
      "Loss : 6.96171397344  Train accuracy :  24.1925  Validation accuracy :  24.36\n",
      "Epoch 25/500 ...........\n",
      "Loss : 6.95728439345  Train accuracy :  24.4125  Validation accuracy :  24.46\n",
      "Epoch 26/500 ...........\n",
      "Loss : 6.95306143333  Train accuracy :  24.6275  Validation accuracy :  24.59\n",
      "Epoch 27/500 ...........\n",
      "Loss : 6.94902462142  Train accuracy :  24.835  Validation accuracy :  24.87\n",
      "Epoch 28/500 ...........\n",
      "Loss : 6.94515416159  Train accuracy :  24.98  Validation accuracy :  25.08\n",
      "Epoch 29/500 ...........\n",
      "Loss : 6.94144453797  Train accuracy :  25.1725  Validation accuracy :  25.25\n",
      "Epoch 30/500 ...........\n",
      "Loss : 6.93788762124  Train accuracy :  25.3425  Validation accuracy :  25.63\n",
      "Epoch 31/500 ...........\n",
      "Loss : 6.93444906488  Train accuracy :  25.565  Validation accuracy :  25.75\n",
      "Epoch 32/500 ...........\n",
      "Loss : 6.93114936467  Train accuracy :  25.7225  Validation accuracy :  25.92\n",
      "Epoch 33/500 ...........\n",
      "Loss : 6.9279578004  Train accuracy :  25.8425  Validation accuracy :  26.0\n",
      "Epoch 34/500 ...........\n",
      "Loss : 6.92488016534  Train accuracy :  26.04  Validation accuracy :  26.26\n",
      "Epoch 35/500 ...........\n",
      "Loss : 6.9219116858  Train accuracy :  26.1975  Validation accuracy :  26.38\n",
      "Epoch 36/500 ...........\n",
      "Loss : 6.9190394467  Train accuracy :  26.3475  Validation accuracy :  26.58\n",
      "Epoch 37/500 ...........\n",
      "Loss : 6.91625789363  Train accuracy :  26.495  Validation accuracy :  26.71\n",
      "Epoch 38/500 ...........\n",
      "Loss : 6.91356698213  Train accuracy :  26.5875  Validation accuracy :  26.78\n",
      "Epoch 39/500 ...........\n",
      "Loss : 6.91094634296  Train accuracy :  26.72  Validation accuracy :  26.85\n",
      "Epoch 40/500 ...........\n",
      "Loss : 6.90841026282  Train accuracy :  26.835  Validation accuracy :  26.99\n",
      "Epoch 41/500 ...........\n",
      "Loss : 6.90595335137  Train accuracy :  26.95  Validation accuracy :  27.08\n",
      "Epoch 42/500 ...........\n",
      "Loss : 6.90355960737  Train accuracy :  27.1075  Validation accuracy :  27.3\n",
      "Epoch 43/500 ...........\n",
      "Loss : 6.90123774526  Train accuracy :  27.2025  Validation accuracy :  27.38\n",
      "Epoch 44/500 ...........\n",
      "Loss : 6.8989814064  Train accuracy :  27.3125  Validation accuracy :  27.42\n",
      "Epoch 45/500 ...........\n",
      "Loss : 6.89677791389  Train accuracy :  27.4475  Validation accuracy :  27.51\n",
      "Epoch 46/500 ...........\n",
      "Loss : 6.89463907356  Train accuracy :  27.5725  Validation accuracy :  27.64\n",
      "Epoch 47/500 ...........\n",
      "Loss : 6.89255044467  Train accuracy :  27.6975  Validation accuracy :  27.67\n",
      "Epoch 48/500 ...........\n",
      "Loss : 6.89053027704  Train accuracy :  27.81  Validation accuracy :  27.74\n",
      "Epoch 49/500 ...........\n",
      "Loss : 6.88853835861  Train accuracy :  27.89  Validation accuracy :  27.81\n",
      "Epoch 50/500 ...........\n",
      "Loss : 6.88661404246  Train accuracy :  28.005  Validation accuracy :  27.87\n",
      "Epoch 51/500 ...........\n",
      "Loss : 6.88472988135  Train accuracy :  28.0725  Validation accuracy :  27.98\n",
      "Epoch 52/500 ...........\n",
      "Loss : 6.88288118343  Train accuracy :  28.18  Validation accuracy :  28.07\n",
      "Epoch 53/500 ...........\n",
      "Loss : 6.88108067017  Train accuracy :  28.295  Validation accuracy :  28.19\n",
      "Epoch 54/500 ...........\n",
      "Loss : 6.87932275692  Train accuracy :  28.38  Validation accuracy :  28.3\n",
      "Epoch 55/500 ...........\n",
      "Loss : 6.8776001367  Train accuracy :  28.4575  Validation accuracy :  28.41\n",
      "Epoch 56/500 ...........\n",
      "Loss : 6.8759208739  Train accuracy :  28.515  Validation accuracy :  28.5\n",
      "Epoch 57/500 ...........\n",
      "Loss : 6.87427583573  Train accuracy :  28.5775  Validation accuracy :  28.59\n",
      "Epoch 58/500 ...........\n",
      "Loss : 6.87266829177  Train accuracy :  28.6675  Validation accuracy :  28.62\n",
      "Epoch 59/500 ...........\n",
      "Loss : 6.87109343842  Train accuracy :  28.7775  Validation accuracy :  28.73\n",
      "Epoch 60/500 ...........\n",
      "Loss : 6.86955198088  Train accuracy :  28.865  Validation accuracy :  28.91\n",
      "Epoch 61/500 ...........\n",
      "Loss : 6.86805220036  Train accuracy :  28.985  Validation accuracy :  29.13\n",
      "Epoch 62/500 ...........\n",
      "Loss : 6.86656458532  Train accuracy :  29.1075  Validation accuracy :  29.19\n",
      "Epoch 63/500 ...........\n",
      "Loss : 6.86511262346  Train accuracy :  29.2225  Validation accuracy :  29.29\n",
      "Epoch 64/500 ...........\n",
      "Loss : 6.86370680235  Train accuracy :  29.2925  Validation accuracy :  29.46\n",
      "Epoch 65/500 ...........\n",
      "Loss : 6.86229847634  Train accuracy :  29.3475  Validation accuracy :  29.6\n",
      "Epoch 66/500 ...........\n",
      "Loss : 6.86092924959  Train accuracy :  29.4675  Validation accuracy :  29.75\n",
      "Epoch 67/500 ...........\n",
      "Loss : 6.85959130373  Train accuracy :  29.5525  Validation accuracy :  29.91\n",
      "Epoch 68/500 ...........\n",
      "Loss : 6.85827161235  Train accuracy :  29.62  Validation accuracy :  29.93\n",
      "Epoch 69/500 ...........\n",
      "Loss : 6.85697829093  Train accuracy :  29.7  Validation accuracy :  29.98\n",
      "Epoch 70/500 ...........\n",
      "Loss : 6.85570955078  Train accuracy :  29.7775  Validation accuracy :  30.05\n",
      "Epoch 71/500 ...........\n",
      "Loss : 6.85446943852  Train accuracy :  29.8475  Validation accuracy :  30.11\n",
      "Epoch 72/500 ...........\n",
      "Loss : 6.85323960892  Train accuracy :  29.9375  Validation accuracy :  30.26\n",
      "Epoch 73/500 ...........\n",
      "Loss : 6.85203209067  Train accuracy :  30.0075  Validation accuracy :  30.29\n",
      "Epoch 74/500 ...........\n",
      "Loss : 6.85085070264  Train accuracy :  30.075  Validation accuracy :  30.31\n",
      "Epoch 75/500 ...........\n",
      "Loss : 6.84968560491  Train accuracy :  30.115  Validation accuracy :  30.39\n",
      "Epoch 76/500 ...........\n",
      "Loss : 6.84854351114  Train accuracy :  30.1825  Validation accuracy :  30.46\n",
      "Epoch 77/500 ...........\n",
      "Loss : 6.84741813588  Train accuracy :  30.27  Validation accuracy :  30.57\n",
      "Epoch 78/500 ...........\n",
      "Loss : 6.84630917583  Train accuracy :  30.3175  Validation accuracy :  30.57\n",
      "Epoch 79/500 ...........\n",
      "Loss : 6.84521851507  Train accuracy :  30.3525  Validation accuracy :  30.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500 ...........\n",
      "Loss : 6.84415779592  Train accuracy :  30.4225  Validation accuracy :  30.62\n",
      "Epoch 81/500 ...........\n",
      "Loss : 6.84309559567  Train accuracy :  30.5175  Validation accuracy :  30.66\n",
      "Epoch 82/500 ...........\n",
      "Loss : 6.84205481269  Train accuracy :  30.6025  Validation accuracy :  30.7\n",
      "Epoch 83/500 ...........\n",
      "Loss : 6.84102948716  Train accuracy :  30.66  Validation accuracy :  30.73\n",
      "Epoch 84/500 ...........\n",
      "Loss : 6.84003146247  Train accuracy :  30.7425  Validation accuracy :  30.78\n",
      "Epoch 85/500 ...........\n",
      "Loss : 6.83903147227  Train accuracy :  30.81  Validation accuracy :  30.84\n",
      "Epoch 86/500 ...........\n",
      "Loss : 6.83805157938  Train accuracy :  30.87  Validation accuracy :  30.93\n",
      "Epoch 87/500 ...........\n",
      "Loss : 6.83708968273  Train accuracy :  30.965  Validation accuracy :  31.0\n",
      "Epoch 88/500 ...........\n",
      "Loss : 6.83613805605  Train accuracy :  31.0075  Validation accuracy :  31.02\n",
      "Epoch 89/500 ...........\n",
      "Loss : 6.83520419945  Train accuracy :  31.0725  Validation accuracy :  31.09\n",
      "Epoch 90/500 ...........\n",
      "Loss : 6.83428783855  Train accuracy :  31.1175  Validation accuracy :  31.19\n",
      "Epoch 91/500 ...........\n",
      "Loss : 6.8333668125  Train accuracy :  31.175  Validation accuracy :  31.26\n",
      "Epoch 92/500 ...........\n",
      "Loss : 6.8324717489  Train accuracy :  31.2025  Validation accuracy :  31.34\n",
      "Epoch 93/500 ...........\n",
      "Loss : 6.83158347948  Train accuracy :  31.2275  Validation accuracy :  31.36\n",
      "Epoch 94/500 ...........\n",
      "Loss : 6.83070969527  Train accuracy :  31.3275  Validation accuracy :  31.38\n",
      "Epoch 95/500 ...........\n",
      "Loss : 6.82984682392  Train accuracy :  31.4  Validation accuracy :  31.37\n",
      "Epoch 96/500 ...........\n",
      "Loss : 6.82900051404  Train accuracy :  31.45  Validation accuracy :  31.46\n",
      "Epoch 97/500 ...........\n",
      "Loss : 6.8281549624  Train accuracy :  31.495  Validation accuracy :  31.52\n",
      "Epoch 98/500 ...........\n",
      "Loss : 6.82733058913  Train accuracy :  31.5375  Validation accuracy :  31.65\n",
      "Epoch 99/500 ...........\n",
      "Loss : 6.8265087573  Train accuracy :  31.61  Validation accuracy :  31.7\n",
      "Epoch 100/500 ...........\n",
      "Loss : 6.82569982285  Train accuracy :  31.6625  Validation accuracy :  31.78\n",
      "Epoch 101/500 ...........\n",
      "Loss : 6.82490200215  Train accuracy :  31.7175  Validation accuracy :  31.77\n",
      "Epoch 102/500 ...........\n",
      "Loss : 6.82411492073  Train accuracy :  31.7525  Validation accuracy :  31.84\n",
      "Epoch 103/500 ...........\n",
      "Loss : 6.8233345795  Train accuracy :  31.7975  Validation accuracy :  31.88\n",
      "Epoch 104/500 ...........\n",
      "Loss : 6.82256559756  Train accuracy :  31.83  Validation accuracy :  31.95\n",
      "Epoch 105/500 ...........\n",
      "Loss : 6.82181003956  Train accuracy :  31.86  Validation accuracy :  31.97\n",
      "Epoch 106/500 ...........\n",
      "Loss : 6.82105623712  Train accuracy :  31.9075  Validation accuracy :  31.93\n",
      "Epoch 107/500 ...........\n",
      "Loss : 6.82031421878  Train accuracy :  31.96  Validation accuracy :  31.97\n",
      "Epoch 108/500 ...........\n",
      "Loss : 6.81958292955  Train accuracy :  32.0025  Validation accuracy :  32.02\n",
      "Epoch 109/500 ...........\n",
      "Loss : 6.8188673799  Train accuracy :  32.055  Validation accuracy :  32.09\n",
      "Epoch 110/500 ...........\n",
      "Loss : 6.81814723187  Train accuracy :  32.0975  Validation accuracy :  32.03\n",
      "Epoch 111/500 ...........\n",
      "Loss : 6.81743649911  Train accuracy :  32.1425  Validation accuracy :  32.03\n",
      "Epoch 112/500 ...........\n",
      "Loss : 6.8167324473  Train accuracy :  32.17  Validation accuracy :  32.06\n",
      "Epoch 113/500 ...........\n",
      "Loss : 6.81604027995  Train accuracy :  32.2475  Validation accuracy :  32.03\n",
      "Epoch 114/500 ...........\n",
      "Loss : 6.81536214362  Train accuracy :  32.3  Validation accuracy :  32.12\n",
      "Epoch 115/500 ...........\n",
      "Loss : 6.81467960208  Train accuracy :  32.3475  Validation accuracy :  32.17\n",
      "Epoch 116/500 ...........\n",
      "Loss : 6.81401441094  Train accuracy :  32.3875  Validation accuracy :  32.2\n",
      "Epoch 117/500 ...........\n",
      "Loss : 6.81334754948  Train accuracy :  32.445  Validation accuracy :  32.27\n",
      "Epoch 118/500 ...........\n",
      "Loss : 6.81269386711  Train accuracy :  32.485  Validation accuracy :  32.34\n",
      "Epoch 119/500 ...........\n",
      "Loss : 6.81204902042  Train accuracy :  32.5325  Validation accuracy :  32.31\n",
      "Epoch 120/500 ...........\n",
      "Loss : 6.81140385264  Train accuracy :  32.585  Validation accuracy :  32.36\n",
      "Epoch 121/500 ...........\n",
      "Loss : 6.81076864404  Train accuracy :  32.6075  Validation accuracy :  32.47\n",
      "Epoch 122/500 ...........\n",
      "Loss : 6.81014213259  Train accuracy :  32.68  Validation accuracy :  32.54\n",
      "Epoch 123/500 ...........\n",
      "Loss : 6.80952879823  Train accuracy :  32.73  Validation accuracy :  32.55\n",
      "Epoch 124/500 ...........\n",
      "Loss : 6.80890537001  Train accuracy :  32.8  Validation accuracy :  32.6\n",
      "Epoch 125/500 ...........\n",
      "Loss : 6.80829670275  Train accuracy :  32.8125  Validation accuracy :  32.64\n",
      "Epoch 126/500 ...........\n",
      "Loss : 6.80769245313  Train accuracy :  32.8625  Validation accuracy :  32.63\n",
      "Epoch 127/500 ...........\n",
      "Loss : 6.8070968981  Train accuracy :  32.8975  Validation accuracy :  32.67\n",
      "Epoch 128/500 ...........\n",
      "Loss : 6.80650812745  Train accuracy :  32.9675  Validation accuracy :  32.69\n",
      "Epoch 129/500 ...........\n",
      "Loss : 6.80592164549  Train accuracy :  33.015  Validation accuracy :  32.75\n",
      "Epoch 130/500 ...........\n",
      "Loss : 6.80534203667  Train accuracy :  33.025  Validation accuracy :  32.76\n",
      "Epoch 131/500 ...........\n",
      "Loss : 6.80476771622  Train accuracy :  33.06  Validation accuracy :  32.78\n",
      "Epoch 132/500 ...........\n",
      "Loss : 6.80420420281  Train accuracy :  33.075  Validation accuracy :  32.81\n",
      "Epoch 133/500 ...........\n",
      "Loss : 6.80363950118  Train accuracy :  33.0875  Validation accuracy :  32.8\n",
      "Epoch 134/500 ...........\n",
      "Loss : 6.80307979163  Train accuracy :  33.1575  Validation accuracy :  32.85\n",
      "Epoch 135/500 ...........\n",
      "Loss : 6.80252741773  Train accuracy :  33.1825  Validation accuracy :  32.88\n",
      "Epoch 136/500 ...........\n",
      "Loss : 6.80198554058  Train accuracy :  33.215  Validation accuracy :  32.94\n",
      "Epoch 137/500 ...........\n",
      "Loss : 6.80143775753  Train accuracy :  33.2275  Validation accuracy :  32.99\n",
      "Epoch 138/500 ...........\n",
      "Loss : 6.80090312499  Train accuracy :  33.2625  Validation accuracy :  33.01\n",
      "Epoch 139/500 ...........\n",
      "Loss : 6.80036903686  Train accuracy :  33.2925  Validation accuracy :  33.02\n",
      "Epoch 140/500 ...........\n",
      "Loss : 6.79985082433  Train accuracy :  33.335  Validation accuracy :  33.04\n",
      "Epoch 141/500 ...........\n",
      "Loss : 6.79931963767  Train accuracy :  33.3725  Validation accuracy :  33.08\n",
      "Epoch 142/500 ...........\n",
      "Loss : 6.79880263539  Train accuracy :  33.37  Validation accuracy :  33.18\n",
      "Epoch 143/500 ...........\n",
      "Loss : 6.79829038755  Train accuracy :  33.405  Validation accuracy :  33.19\n",
      "Epoch 144/500 ...........\n",
      "Loss : 6.79779467468  Train accuracy :  33.4325  Validation accuracy :  33.19\n",
      "Epoch 145/500 ...........\n",
      "Loss : 6.79728349448  Train accuracy :  33.4775  Validation accuracy :  33.21\n",
      "Epoch 146/500 ...........\n",
      "Loss : 6.79677786369  Train accuracy :  33.4775  Validation accuracy :  33.29\n",
      "Epoch 147/500 ...........\n",
      "Loss : 6.7962835363  Train accuracy :  33.5075  Validation accuracy :  33.31\n",
      "Epoch 148/500 ...........\n",
      "Loss : 6.79579224573  Train accuracy :  33.555  Validation accuracy :  33.22\n",
      "Epoch 149/500 ...........\n",
      "Loss : 6.79530582976  Train accuracy :  33.5725  Validation accuracy :  33.26\n",
      "Epoch 150/500 ...........\n",
      "Loss : 6.79482384549  Train accuracy :  33.585  Validation accuracy :  33.29\n",
      "Epoch 151/500 ...........\n",
      "Loss : 6.79434452745  Train accuracy :  33.63  Validation accuracy :  33.31\n",
      "Epoch 152/500 ...........\n",
      "Loss : 6.79387026114  Train accuracy :  33.66  Validation accuracy :  33.31\n",
      "Epoch 153/500 ...........\n",
      "Loss : 6.79340521165  Train accuracy :  33.7225  Validation accuracy :  33.39\n",
      "Epoch 154/500 ...........\n",
      "Loss : 6.79293720162  Train accuracy :  33.73  Validation accuracy :  33.4\n",
      "Epoch 155/500 ...........\n",
      "Loss : 6.79247019117  Train accuracy :  33.7975  Validation accuracy :  33.41\n",
      "Epoch 156/500 ...........\n",
      "Loss : 6.79201332626  Train accuracy :  33.865  Validation accuracy :  33.47\n",
      "Epoch 157/500 ...........\n",
      "Loss : 6.7915556562  Train accuracy :  33.855  Validation accuracy :  33.45\n",
      "Epoch 158/500 ...........\n",
      "Loss : 6.79110457727  Train accuracy :  33.9  Validation accuracy :  33.51\n",
      "Epoch 159/500 ...........\n",
      "Loss : 6.79065703757  Train accuracy :  33.925  Validation accuracy :  33.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/500 ...........\n",
      "Loss : 6.79021897062  Train accuracy :  33.955  Validation accuracy :  33.54\n",
      "Epoch 161/500 ...........\n",
      "Loss : 6.78977533271  Train accuracy :  33.9875  Validation accuracy :  33.54\n",
      "Epoch 162/500 ...........\n",
      "Loss : 6.78933649135  Train accuracy :  34.005  Validation accuracy :  33.6\n",
      "Epoch 163/500 ...........\n",
      "Loss : 6.78890174574  Train accuracy :  34.025  Validation accuracy :  33.64\n",
      "Epoch 164/500 ...........\n",
      "Loss : 6.78847510405  Train accuracy :  34.0425  Validation accuracy :  33.64\n",
      "Epoch 165/500 ...........\n",
      "Loss : 6.78805016246  Train accuracy :  34.1025  Validation accuracy :  33.69\n",
      "Epoch 166/500 ...........\n",
      "Loss : 6.78763904807  Train accuracy :  34.1125  Validation accuracy :  33.71\n",
      "Epoch 167/500 ...........\n",
      "Loss : 6.78720162821  Train accuracy :  34.1425  Validation accuracy :  33.73\n",
      "Epoch 168/500 ...........\n",
      "Loss : 6.78678549207  Train accuracy :  34.22  Validation accuracy :  33.79\n",
      "Epoch 169/500 ...........\n",
      "Loss : 6.78637244977  Train accuracy :  34.2225  Validation accuracy :  33.83\n",
      "Epoch 170/500 ...........\n",
      "Loss : 6.78596137284  Train accuracy :  34.26  Validation accuracy :  33.83\n",
      "Epoch 171/500 ...........\n",
      "Loss : 6.78555356946  Train accuracy :  34.3  Validation accuracy :  33.89\n",
      "Epoch 172/500 ...........\n",
      "Loss : 6.78514907759  Train accuracy :  34.3175  Validation accuracy :  33.91\n",
      "Epoch 173/500 ...........\n",
      "Loss : 6.78474855188  Train accuracy :  34.3275  Validation accuracy :  33.91\n",
      "Epoch 174/500 ...........\n",
      "Loss : 6.78435323118  Train accuracy :  34.34  Validation accuracy :  33.96\n",
      "Epoch 175/500 ...........\n",
      "Loss : 6.783955885  Train accuracy :  34.385  Validation accuracy :  33.95\n",
      "Epoch 176/500 ...........\n",
      "Loss : 6.78357824765  Train accuracy :  34.43  Validation accuracy :  33.97\n",
      "Epoch 177/500 ...........\n",
      "Loss : 6.78318424027  Train accuracy :  34.49  Validation accuracy :  33.98\n",
      "Epoch 178/500 ...........\n",
      "Loss : 6.7827886679  Train accuracy :  34.4975  Validation accuracy :  34.04\n",
      "Epoch 179/500 ...........\n",
      "Loss : 6.78240296286  Train accuracy :  34.5225  Validation accuracy :  34.04\n",
      "Epoch 180/500 ...........\n",
      "Loss : 6.78202159841  Train accuracy :  34.5375  Validation accuracy :  34.09\n",
      "Epoch 181/500 ...........\n",
      "Loss : 6.78164399626  Train accuracy :  34.56  Validation accuracy :  34.11\n",
      "Epoch 182/500 ...........\n",
      "Loss : 6.78126801382  Train accuracy :  34.5625  Validation accuracy :  34.11\n",
      "Epoch 183/500 ...........\n",
      "Loss : 6.7808949414  Train accuracy :  34.5925  Validation accuracy :  34.18\n",
      "Epoch 184/500 ...........\n",
      "Loss : 6.78052671056  Train accuracy :  34.615  Validation accuracy :  34.08\n",
      "Epoch 185/500 ...........\n",
      "Loss : 6.78015702336  Train accuracy :  34.645  Validation accuracy :  34.17\n",
      "Epoch 186/500 ...........\n",
      "Loss : 6.77980410654  Train accuracy :  34.7025  Validation accuracy :  34.19\n",
      "Epoch 187/500 ...........\n",
      "Loss : 6.7794331831  Train accuracy :  34.6975  Validation accuracy :  34.14\n",
      "Epoch 188/500 ...........\n",
      "Loss : 6.7790705457  Train accuracy :  34.7275  Validation accuracy :  34.18\n",
      "Epoch 189/500 ...........\n",
      "Loss : 6.77871217842  Train accuracy :  34.7675  Validation accuracy :  34.21\n",
      "Epoch 190/500 ...........\n",
      "Loss : 6.77837026468  Train accuracy :  34.7775  Validation accuracy :  34.28\n",
      "Epoch 191/500 ...........\n",
      "Loss : 6.77802995461  Train accuracy :  34.78  Validation accuracy :  34.24\n",
      "Epoch 192/500 ...........\n",
      "Loss : 6.77765965895  Train accuracy :  34.8175  Validation accuracy :  34.33\n",
      "Epoch 193/500 ...........\n",
      "Loss : 6.777308475  Train accuracy :  34.8475  Validation accuracy :  34.33\n",
      "Epoch 194/500 ...........\n",
      "Loss : 6.77696140075  Train accuracy :  34.85  Validation accuracy :  34.36\n",
      "Epoch 195/500 ...........\n",
      "Loss : 6.77662286046  Train accuracy :  34.86  Validation accuracy :  34.34\n",
      "Epoch 196/500 ...........\n",
      "Loss : 6.77627847415  Train accuracy :  34.8875  Validation accuracy :  34.44\n",
      "Epoch 197/500 ...........\n",
      "Loss : 6.77593902155  Train accuracy :  34.91  Validation accuracy :  34.47\n",
      "Epoch 198/500 ...........\n",
      "Loss : 6.77560288981  Train accuracy :  34.94  Validation accuracy :  34.46\n",
      "Epoch 199/500 ...........\n",
      "Loss : 6.7752715416  Train accuracy :  34.96  Validation accuracy :  34.51\n",
      "Epoch 200/500 ...........\n",
      "Loss : 6.77493895968  Train accuracy :  34.985  Validation accuracy :  34.51\n",
      "Epoch 201/500 ...........\n",
      "Loss : 6.77461190668  Train accuracy :  35.0125  Validation accuracy :  34.54\n",
      "Epoch 202/500 ...........\n",
      "Loss : 6.77428106431  Train accuracy :  35.0275  Validation accuracy :  34.57\n",
      "Epoch 203/500 ...........\n",
      "Loss : 6.77395516693  Train accuracy :  35.05  Validation accuracy :  34.56\n",
      "Epoch 204/500 ...........\n",
      "Loss : 6.77363292799  Train accuracy :  35.0675  Validation accuracy :  34.61\n",
      "Epoch 205/500 ...........\n",
      "Loss : 6.77331475777  Train accuracy :  35.095  Validation accuracy :  34.65\n",
      "Epoch 206/500 ...........\n",
      "Loss : 6.77299695806  Train accuracy :  35.11  Validation accuracy :  34.65\n",
      "Epoch 207/500 ...........\n",
      "Loss : 6.77267576549  Train accuracy :  35.11  Validation accuracy :  34.71\n",
      "Epoch 208/500 ...........\n",
      "Loss : 6.7723618241  Train accuracy :  35.1575  Validation accuracy :  34.72\n",
      "Epoch 209/500 ...........\n",
      "Loss : 6.77204729392  Train accuracy :  35.1675  Validation accuracy :  34.71\n",
      "Epoch 210/500 ...........\n",
      "Loss : 6.7717414939  Train accuracy :  35.165  Validation accuracy :  34.72\n",
      "Epoch 211/500 ...........\n",
      "Loss : 6.77143104105  Train accuracy :  35.2  Validation accuracy :  34.79\n",
      "Epoch 212/500 ...........\n",
      "Loss : 6.77112265146  Train accuracy :  35.2025  Validation accuracy :  34.8\n",
      "Epoch 213/500 ...........\n",
      "Loss : 6.77081746473  Train accuracy :  35.2275  Validation accuracy :  34.81\n",
      "Epoch 214/500 ...........\n",
      "Loss : 6.77051305394  Train accuracy :  35.265  Validation accuracy :  34.75\n",
      "Epoch 215/500 ...........\n",
      "Loss : 6.77021167958  Train accuracy :  35.24  Validation accuracy :  34.75\n",
      "Epoch 216/500 ...........\n",
      "Loss : 6.76991196611  Train accuracy :  35.27  Validation accuracy :  34.85\n",
      "Epoch 217/500 ...........\n",
      "Loss : 6.76961355584  Train accuracy :  35.27  Validation accuracy :  34.87\n",
      "Epoch 218/500 ...........\n",
      "Loss : 6.76931768708  Train accuracy :  35.31  Validation accuracy :  34.89\n",
      "Epoch 219/500 ...........\n",
      "Loss : 6.7690260749  Train accuracy :  35.32  Validation accuracy :  34.91\n",
      "Epoch 220/500 ...........\n",
      "Loss : 6.76873272695  Train accuracy :  35.335  Validation accuracy :  34.9\n",
      "Epoch 221/500 ...........\n",
      "Loss : 6.76844669066  Train accuracy :  35.335  Validation accuracy :  34.85\n",
      "Epoch 222/500 ...........\n",
      "Loss : 6.76815933785  Train accuracy :  35.385  Validation accuracy :  34.91\n",
      "Epoch 223/500 ...........\n",
      "Loss : 6.76787300464  Train accuracy :  35.3975  Validation accuracy :  34.95\n",
      "Epoch 224/500 ...........\n",
      "Loss : 6.76758458369  Train accuracy :  35.4025  Validation accuracy :  34.97\n",
      "Epoch 225/500 ...........\n",
      "Loss : 6.76729842932  Train accuracy :  35.44  Validation accuracy :  34.96\n",
      "Epoch 226/500 ...........\n",
      "Loss : 6.76701453055  Train accuracy :  35.47  Validation accuracy :  35.01\n",
      "Epoch 227/500 ...........\n",
      "Loss : 6.76673593581  Train accuracy :  35.47  Validation accuracy :  35.03\n",
      "Epoch 228/500 ...........\n",
      "Loss : 6.7664608593  Train accuracy :  35.505  Validation accuracy :  35.07\n",
      "Epoch 229/500 ...........\n",
      "Loss : 6.76618117033  Train accuracy :  35.535  Validation accuracy :  35.11\n",
      "Epoch 230/500 ...........\n",
      "Loss : 6.76590748543  Train accuracy :  35.545  Validation accuracy :  35.12\n",
      "Epoch 231/500 ...........\n",
      "Loss : 6.76563328432  Train accuracy :  35.5625  Validation accuracy :  35.08\n",
      "Epoch 232/500 ...........\n",
      "Loss : 6.76535902692  Train accuracy :  35.58  Validation accuracy :  35.14\n",
      "Epoch 233/500 ...........\n",
      "Loss : 6.76509036435  Train accuracy :  35.5925  Validation accuracy :  35.1\n",
      "Epoch 234/500 ...........\n",
      "Loss : 6.76481944603  Train accuracy :  35.6125  Validation accuracy :  35.13\n",
      "Epoch 235/500 ...........\n",
      "Loss : 6.76455244267  Train accuracy :  35.6325  Validation accuracy :  35.12\n",
      "Epoch 236/500 ...........\n",
      "Loss : 6.7642868126  Train accuracy :  35.6575  Validation accuracy :  35.18\n",
      "Epoch 237/500 ...........\n",
      "Loss : 6.76402576777  Train accuracy :  35.705  Validation accuracy :  35.21\n",
      "Epoch 238/500 ...........\n",
      "Loss : 6.76376759235  Train accuracy :  35.73  Validation accuracy :  35.2\n",
      "Epoch 239/500 ...........\n",
      "Loss : 6.76349864528  Train accuracy :  35.7375  Validation accuracy :  35.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/500 ...........\n",
      "Loss : 6.76323741423  Train accuracy :  35.75  Validation accuracy :  35.25\n",
      "Epoch 241/500 ...........\n",
      "Loss : 6.76298026885  Train accuracy :  35.785  Validation accuracy :  35.22\n",
      "Epoch 242/500 ...........\n",
      "Loss : 6.76272393436  Train accuracy :  35.8025  Validation accuracy :  35.26\n",
      "Epoch 243/500 ...........\n",
      "Loss : 6.76246663014  Train accuracy :  35.7975  Validation accuracy :  35.27\n",
      "Epoch 244/500 ...........\n",
      "Loss : 6.76221596526  Train accuracy :  35.8225  Validation accuracy :  35.31\n",
      "Epoch 245/500 ...........\n",
      "Loss : 6.76196222417  Train accuracy :  35.825  Validation accuracy :  35.27\n",
      "Epoch 246/500 ...........\n",
      "Loss : 6.7617161788  Train accuracy :  35.8525  Validation accuracy :  35.27\n",
      "Epoch 247/500 ...........\n",
      "Loss : 6.76145829621  Train accuracy :  35.8725  Validation accuracy :  35.24\n",
      "Epoch 248/500 ...........\n",
      "Loss : 6.76120921332  Train accuracy :  35.88  Validation accuracy :  35.24\n",
      "Epoch 249/500 ...........\n",
      "Loss : 6.76096604225  Train accuracy :  35.8875  Validation accuracy :  35.26\n",
      "Epoch 250/500 ...........\n",
      "Loss : 6.76071603251  Train accuracy :  35.905  Validation accuracy :  35.28\n",
      "Epoch 251/500 ...........\n",
      "Loss : 6.76047045878  Train accuracy :  35.9175  Validation accuracy :  35.3\n",
      "Epoch 252/500 ...........\n",
      "Loss : 6.76022901664  Train accuracy :  35.9275  Validation accuracy :  35.29\n",
      "Epoch 253/500 ...........\n",
      "Loss : 6.75999030708  Train accuracy :  35.9425  Validation accuracy :  35.35\n",
      "Epoch 254/500 ...........\n",
      "Loss : 6.75975160855  Train accuracy :  35.9625  Validation accuracy :  35.32\n",
      "Epoch 255/500 ...........\n",
      "Loss : 6.75950754656  Train accuracy :  35.9675  Validation accuracy :  35.32\n",
      "Epoch 256/500 ...........\n",
      "Loss : 6.75926797115  Train accuracy :  35.9825  Validation accuracy :  35.34\n",
      "Epoch 257/500 ...........\n",
      "Loss : 6.75904130562  Train accuracy :  35.985  Validation accuracy :  35.39\n",
      "Epoch 258/500 ...........\n",
      "Loss : 6.75880508465  Train accuracy :  36.0475  Validation accuracy :  35.38\n",
      "Epoch 259/500 ...........\n",
      "Loss : 6.75855982487  Train accuracy :  36.0275  Validation accuracy :  35.42\n",
      "Epoch 260/500 ...........\n",
      "Loss : 6.75832844497  Train accuracy :  36.03  Validation accuracy :  35.46\n",
      "Epoch 261/500 ...........\n",
      "Loss : 6.75809611245  Train accuracy :  36.0625  Validation accuracy :  35.48\n",
      "Epoch 262/500 ...........\n",
      "Loss : 6.75786478963  Train accuracy :  36.0775  Validation accuracy :  35.5\n",
      "Epoch 263/500 ...........\n",
      "Loss : 6.75763466914  Train accuracy :  36.105  Validation accuracy :  35.48\n",
      "Epoch 264/500 ...........\n",
      "Loss : 6.75740651606  Train accuracy :  36.145  Validation accuracy :  35.5\n",
      "Epoch 265/500 ...........\n",
      "Loss : 6.75718303848  Train accuracy :  36.1575  Validation accuracy :  35.57\n",
      "Epoch 266/500 ...........\n",
      "Loss : 6.75697245148  Train accuracy :  36.1925  Validation accuracy :  35.54\n",
      "Epoch 267/500 ...........\n",
      "Loss : 6.75673799481  Train accuracy :  36.21  Validation accuracy :  35.58\n",
      "Epoch 268/500 ...........\n",
      "Loss : 6.75650616105  Train accuracy :  36.24  Validation accuracy :  35.6\n",
      "Epoch 269/500 ...........\n",
      "Loss : 6.75628153926  Train accuracy :  36.2625  Validation accuracy :  35.64\n",
      "Epoch 270/500 ...........\n",
      "Loss : 6.75606020779  Train accuracy :  36.2775  Validation accuracy :  35.74\n",
      "Epoch 271/500 ...........\n",
      "Loss : 6.75584402195  Train accuracy :  36.3  Validation accuracy :  35.73\n",
      "Epoch 272/500 ...........\n",
      "Loss : 6.75562443615  Train accuracy :  36.32  Validation accuracy :  35.72\n",
      "Epoch 273/500 ...........\n",
      "Loss : 6.75540629409  Train accuracy :  36.3125  Validation accuracy :  35.66\n",
      "Epoch 274/500 ...........\n",
      "Loss : 6.7551898319  Train accuracy :  36.3375  Validation accuracy :  35.71\n",
      "Epoch 275/500 ...........\n",
      "Loss : 6.75497150374  Train accuracy :  36.355  Validation accuracy :  35.69\n",
      "Epoch 276/500 ...........\n",
      "Loss : 6.75475790005  Train accuracy :  36.365  Validation accuracy :  35.71\n",
      "Epoch 277/500 ...........\n",
      "Loss : 6.75454725314  Train accuracy :  36.3875  Validation accuracy :  35.71\n",
      "Epoch 278/500 ...........\n",
      "Loss : 6.75433420604  Train accuracy :  36.3925  Validation accuracy :  35.72\n",
      "Epoch 279/500 ...........\n",
      "Loss : 6.75412994255  Train accuracy :  36.4175  Validation accuracy :  35.72\n",
      "Epoch 280/500 ...........\n",
      "Loss : 6.75390625816  Train accuracy :  36.4225  Validation accuracy :  35.78\n",
      "Epoch 281/500 ...........\n",
      "Loss : 6.75369775777  Train accuracy :  36.43  Validation accuracy :  35.74\n",
      "Epoch 282/500 ...........\n",
      "Loss : 6.75348834927  Train accuracy :  36.4725  Validation accuracy :  35.72\n",
      "Epoch 283/500 ...........\n",
      "Loss : 6.75328090964  Train accuracy :  36.495  Validation accuracy :  35.74\n",
      "Epoch 284/500 ...........\n",
      "Loss : 6.75307319648  Train accuracy :  36.4925  Validation accuracy :  35.74\n",
      "Epoch 285/500 ...........\n",
      "Loss : 6.75287171495  Train accuracy :  36.525  Validation accuracy :  35.78\n",
      "Epoch 286/500 ...........\n",
      "Loss : 6.75266641035  Train accuracy :  36.54  Validation accuracy :  35.74\n",
      "Epoch 287/500 ...........\n",
      "Loss : 6.75245916965  Train accuracy :  36.555  Validation accuracy :  35.7\n",
      "Epoch 288/500 ...........\n",
      "Loss : 6.75225615148  Train accuracy :  36.5575  Validation accuracy :  35.75\n",
      "Epoch 289/500 ...........\n",
      "Loss : 6.75205425875  Train accuracy :  36.5925  Validation accuracy :  35.77\n",
      "Epoch 290/500 ...........\n",
      "Loss : 6.75185791341  Train accuracy :  36.6075  Validation accuracy :  35.76\n",
      "Epoch 291/500 ...........\n",
      "Loss : 6.75165409965  Train accuracy :  36.6125  Validation accuracy :  35.77\n",
      "Epoch 292/500 ...........\n",
      "Loss : 6.75145881701  Train accuracy :  36.625  Validation accuracy :  35.78\n",
      "Epoch 293/500 ...........\n",
      "Loss : 6.7512568106  Train accuracy :  36.6475  Validation accuracy :  35.79\n",
      "Epoch 294/500 ...........\n",
      "Loss : 6.75106388119  Train accuracy :  36.6725  Validation accuracy :  35.81\n",
      "Epoch 295/500 ...........\n",
      "Loss : 6.750863962  Train accuracy :  36.6925  Validation accuracy :  35.82\n",
      "Epoch 296/500 ...........\n",
      "Loss : 6.75066858187  Train accuracy :  36.7075  Validation accuracy :  35.85\n",
      "Epoch 297/500 ...........\n",
      "Loss : 6.75047472283  Train accuracy :  36.7125  Validation accuracy :  35.82\n",
      "Epoch 298/500 ...........\n",
      "Loss : 6.750281317  Train accuracy :  36.73  Validation accuracy :  35.81\n",
      "Epoch 299/500 ...........\n",
      "Loss : 6.75008897469  Train accuracy :  36.7375  Validation accuracy :  35.86\n",
      "Epoch 300/500 ...........\n",
      "Loss : 6.74989637698  Train accuracy :  36.75  Validation accuracy :  35.83\n",
      "Epoch 301/500 ...........\n",
      "Loss : 6.74970444517  Train accuracy :  36.7625  Validation accuracy :  35.79\n",
      "Epoch 302/500 ...........\n",
      "Loss : 6.74951378091  Train accuracy :  36.79  Validation accuracy :  35.82\n",
      "Epoch 303/500 ...........\n",
      "Loss : 6.74932628292  Train accuracy :  36.815  Validation accuracy :  35.82\n",
      "Epoch 304/500 ...........\n",
      "Loss : 6.74915118575  Train accuracy :  36.8375  Validation accuracy :  35.84\n",
      "Epoch 305/500 ...........\n",
      "Loss : 6.74895241552  Train accuracy :  36.8275  Validation accuracy :  35.87\n",
      "Epoch 306/500 ...........\n",
      "Loss : 6.74876773466  Train accuracy :  36.835  Validation accuracy :  35.9\n",
      "Epoch 307/500 ...........\n",
      "Loss : 6.74857906208  Train accuracy :  36.8775  Validation accuracy :  35.91\n",
      "Epoch 308/500 ...........\n",
      "Loss : 6.74839474514  Train accuracy :  36.8875  Validation accuracy :  35.88\n",
      "Epoch 309/500 ...........\n",
      "Loss : 6.7482161408  Train accuracy :  36.9  Validation accuracy :  35.87\n",
      "Epoch 310/500 ...........\n",
      "Loss : 6.74802676442  Train accuracy :  36.9  Validation accuracy :  35.91\n",
      "Epoch 311/500 ...........\n",
      "Loss : 6.74784413023  Train accuracy :  36.92  Validation accuracy :  35.92\n",
      "Epoch 312/500 ...........\n",
      "Loss : 6.74766616621  Train accuracy :  36.9375  Validation accuracy :  35.93\n",
      "Epoch 313/500 ...........\n",
      "Loss : 6.74748508006  Train accuracy :  36.935  Validation accuracy :  35.93\n",
      "Epoch 314/500 ...........\n",
      "Loss : 6.74730475938  Train accuracy :  36.965  Validation accuracy :  35.95\n",
      "Epoch 315/500 ...........\n",
      "Loss : 6.74712755269  Train accuracy :  36.9825  Validation accuracy :  35.98\n",
      "Epoch 316/500 ...........\n",
      "Loss : 6.7469430484  Train accuracy :  36.9925  Validation accuracy :  35.95\n",
      "Epoch 317/500 ...........\n",
      "Loss : 6.74677050814  Train accuracy :  37.02  Validation accuracy :  35.96\n",
      "Epoch 318/500 ...........\n",
      "Loss : 6.74658957982  Train accuracy :  37.045  Validation accuracy :  36.0\n",
      "Epoch 319/500 ...........\n",
      "Loss : 6.74641802782  Train accuracy :  37.055  Validation accuracy :  36.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/500 ...........\n",
      "Loss : 6.74623745065  Train accuracy :  37.075  Validation accuracy :  35.98\n",
      "Epoch 321/500 ...........\n",
      "Loss : 6.74606260343  Train accuracy :  37.0975  Validation accuracy :  35.96\n",
      "Epoch 322/500 ...........\n",
      "Loss : 6.74588832447  Train accuracy :  37.12  Validation accuracy :  35.98\n",
      "Epoch 323/500 ...........\n",
      "Loss : 6.74571626802  Train accuracy :  37.11  Validation accuracy :  36.0\n",
      "Epoch 324/500 ...........\n",
      "Loss : 6.74554642706  Train accuracy :  37.145  Validation accuracy :  35.94\n",
      "Epoch 325/500 ...........\n",
      "Loss : 6.74537068311  Train accuracy :  37.135  Validation accuracy :  35.92\n",
      "Epoch 326/500 ...........\n",
      "Loss : 6.74520440166  Train accuracy :  37.16  Validation accuracy :  35.92\n",
      "Epoch 327/500 ...........\n",
      "Loss : 6.74503121101  Train accuracy :  37.1575  Validation accuracy :  35.96\n",
      "Epoch 328/500 ...........\n",
      "Loss : 6.74486217465  Train accuracy :  37.1875  Validation accuracy :  35.93\n",
      "Epoch 329/500 ...........\n",
      "Loss : 6.74469183164  Train accuracy :  37.215  Validation accuracy :  35.95\n",
      "Epoch 330/500 ...........\n",
      "Loss : 6.74452522327  Train accuracy :  37.2075  Validation accuracy :  35.96\n",
      "Epoch 331/500 ...........\n",
      "Loss : 6.74435759202  Train accuracy :  37.23  Validation accuracy :  35.96\n",
      "Epoch 332/500 ...........\n",
      "Loss : 6.74419402255  Train accuracy :  37.245  Validation accuracy :  35.97\n",
      "Epoch 333/500 ...........\n",
      "Loss : 6.744026576  Train accuracy :  37.2275  Validation accuracy :  35.97\n",
      "Epoch 334/500 ...........\n",
      "Loss : 6.74386067186  Train accuracy :  37.2525  Validation accuracy :  35.97\n",
      "Epoch 335/500 ...........\n",
      "Loss : 6.74369306993  Train accuracy :  37.27  Validation accuracy :  36.0\n",
      "Epoch 336/500 ...........\n",
      "Loss : 6.7435323984  Train accuracy :  37.295  Validation accuracy :  36.02\n",
      "Epoch 337/500 ...........\n",
      "Loss : 6.74336992404  Train accuracy :  37.315  Validation accuracy :  36.01\n",
      "Epoch 338/500 ...........\n",
      "Loss : 6.74320824998  Train accuracy :  37.3325  Validation accuracy :  36.06\n",
      "Epoch 339/500 ...........\n",
      "Loss : 6.74305676873  Train accuracy :  37.335  Validation accuracy :  36.01\n",
      "Epoch 340/500 ...........\n",
      "Loss : 6.74288554295  Train accuracy :  37.3625  Validation accuracy :  36.03\n",
      "Epoch 341/500 ...........\n",
      "Loss : 6.74272073921  Train accuracy :  37.355  Validation accuracy :  36.04\n",
      "Epoch 342/500 ...........\n",
      "Loss : 6.74256025485  Train accuracy :  37.39  Validation accuracy :  36.03\n",
      "Epoch 343/500 ...........\n",
      "Loss : 6.74240786659  Train accuracy :  37.41  Validation accuracy :  36.05\n",
      "Epoch 344/500 ...........\n",
      "Loss : 6.74224715722  Train accuracy :  37.4325  Validation accuracy :  36.08\n",
      "Epoch 345/500 ...........\n",
      "Loss : 6.742089392  Train accuracy :  37.4225  Validation accuracy :  36.05\n",
      "Epoch 346/500 ...........\n",
      "Loss : 6.74192700695  Train accuracy :  37.45  Validation accuracy :  36.05\n",
      "Epoch 347/500 ...........\n",
      "Loss : 6.74177071213  Train accuracy :  37.4425  Validation accuracy :  36.07\n",
      "Epoch 348/500 ...........\n",
      "Loss : 6.74162931069  Train accuracy :  37.475  Validation accuracy :  36.07\n",
      "Epoch 349/500 ...........\n",
      "Loss : 6.74145714448  Train accuracy :  37.48  Validation accuracy :  36.02\n",
      "Epoch 350/500 ...........\n",
      "Loss : 6.74130764093  Train accuracy :  37.495  Validation accuracy :  36.08\n",
      "Epoch 351/500 ...........\n",
      "Loss : 6.74115926448  Train accuracy :  37.5275  Validation accuracy :  36.08\n",
      "Epoch 352/500 ...........\n",
      "Loss : 6.74100225449  Train accuracy :  37.54  Validation accuracy :  36.09\n",
      "Epoch 353/500 ...........\n",
      "Loss : 6.74085539948  Train accuracy :  37.5325  Validation accuracy :  36.06\n",
      "Epoch 354/500 ...........\n",
      "Loss : 6.7406963381  Train accuracy :  37.55  Validation accuracy :  36.11\n",
      "Epoch 355/500 ...........\n",
      "Loss : 6.74054831648  Train accuracy :  37.5525  Validation accuracy :  36.07\n",
      "Epoch 356/500 ...........\n",
      "Loss : 6.74038865766  Train accuracy :  37.5675  Validation accuracy :  36.09\n",
      "Epoch 357/500 ...........\n",
      "Loss : 6.74023659883  Train accuracy :  37.57  Validation accuracy :  36.09\n",
      "Epoch 358/500 ...........\n",
      "Loss : 6.74008380123  Train accuracy :  37.56  Validation accuracy :  36.06\n",
      "Epoch 359/500 ...........\n",
      "Loss : 6.73993821109  Train accuracy :  37.585  Validation accuracy :  36.05\n",
      "Epoch 360/500 ...........\n",
      "Loss : 6.73979024108  Train accuracy :  37.6025  Validation accuracy :  36.13\n",
      "Epoch 361/500 ...........\n",
      "Loss : 6.73964095117  Train accuracy :  37.62  Validation accuracy :  36.15\n",
      "Epoch 362/500 ...........\n",
      "Loss : 6.73949526771  Train accuracy :  37.635  Validation accuracy :  36.09\n",
      "Epoch 363/500 ...........\n",
      "Loss : 6.73934471336  Train accuracy :  37.6375  Validation accuracy :  36.11\n",
      "Epoch 364/500 ...........\n",
      "Loss : 6.73920061029  Train accuracy :  37.6625  Validation accuracy :  36.1\n",
      "Epoch 365/500 ...........\n",
      "Loss : 6.73905257195  Train accuracy :  37.66  Validation accuracy :  36.1\n",
      "Epoch 366/500 ...........\n",
      "Loss : 6.73890706117  Train accuracy :  37.6775  Validation accuracy :  36.1\n",
      "Epoch 367/500 ...........\n",
      "Loss : 6.73876406733  Train accuracy :  37.675  Validation accuracy :  36.06\n",
      "Epoch 368/500 ...........\n",
      "Loss : 6.73861582342  Train accuracy :  37.685  Validation accuracy :  36.12\n",
      "Epoch 369/500 ...........\n",
      "Loss : 6.7384824995  Train accuracy :  37.6725  Validation accuracy :  36.15\n",
      "Epoch 370/500 ...........\n",
      "Loss : 6.73834913524  Train accuracy :  37.685  Validation accuracy :  36.15\n",
      "Epoch 371/500 ...........\n",
      "Loss : 6.73818449409  Train accuracy :  37.6875  Validation accuracy :  36.18\n",
      "Epoch 372/500 ...........\n",
      "Loss : 6.73804182855  Train accuracy :  37.7075  Validation accuracy :  36.2\n",
      "Epoch 373/500 ...........\n",
      "Loss : 6.73790063801  Train accuracy :  37.7225  Validation accuracy :  36.22\n",
      "Epoch 374/500 ...........\n",
      "Loss : 6.73775825474  Train accuracy :  37.7125  Validation accuracy :  36.2\n",
      "Epoch 375/500 ...........\n",
      "Loss : 6.7376240137  Train accuracy :  37.755  Validation accuracy :  36.23\n",
      "Epoch 376/500 ...........\n",
      "Loss : 6.73748438902  Train accuracy :  37.7675  Validation accuracy :  36.22\n",
      "Epoch 377/500 ...........\n",
      "Loss : 6.73734167995  Train accuracy :  37.7725  Validation accuracy :  36.26\n",
      "Epoch 378/500 ...........\n",
      "Loss : 6.73719821707  Train accuracy :  37.7675  Validation accuracy :  36.31\n",
      "Epoch 379/500 ...........\n",
      "Loss : 6.73707236596  Train accuracy :  37.775  Validation accuracy :  36.31\n",
      "Epoch 380/500 ...........\n",
      "Loss : 6.73692082854  Train accuracy :  37.7675  Validation accuracy :  36.3\n",
      "Epoch 381/500 ...........\n",
      "Loss : 6.73678270109  Train accuracy :  37.7875  Validation accuracy :  36.28\n",
      "Epoch 382/500 ...........\n",
      "Loss : 6.73667001301  Train accuracy :  37.815  Validation accuracy :  36.33\n",
      "Epoch 383/500 ...........\n",
      "Loss : 6.73651096372  Train accuracy :  37.8025  Validation accuracy :  36.33\n",
      "Epoch 384/500 ...........\n",
      "Loss : 6.73637245836  Train accuracy :  37.805  Validation accuracy :  36.34\n",
      "Epoch 385/500 ...........\n",
      "Loss : 6.73623815514  Train accuracy :  37.8125  Validation accuracy :  36.34\n",
      "Epoch 386/500 ...........\n",
      "Loss : 6.73610164595  Train accuracy :  37.8125  Validation accuracy :  36.33\n",
      "Epoch 387/500 ...........\n",
      "Loss : 6.73596674721  Train accuracy :  37.835  Validation accuracy :  36.33\n",
      "Epoch 388/500 ...........\n",
      "Loss : 6.73583415015  Train accuracy :  37.8525  Validation accuracy :  36.4\n",
      "Epoch 389/500 ...........\n",
      "Loss : 6.73570845026  Train accuracy :  37.8525  Validation accuracy :  36.39\n",
      "Epoch 390/500 ...........\n",
      "Loss : 6.73556614482  Train accuracy :  37.85  Validation accuracy :  36.37\n",
      "Epoch 391/500 ...........\n",
      "Loss : 6.73544425801  Train accuracy :  37.8675  Validation accuracy :  36.37\n",
      "Epoch 392/500 ...........\n",
      "Loss : 6.73530149479  Train accuracy :  37.865  Validation accuracy :  36.36\n",
      "Epoch 393/500 ...........\n",
      "Loss : 6.73517186459  Train accuracy :  37.89  Validation accuracy :  36.36\n",
      "Epoch 394/500 ...........\n",
      "Loss : 6.73503621451  Train accuracy :  37.8975  Validation accuracy :  36.41\n",
      "Epoch 395/500 ...........\n",
      "Loss : 6.734905099  Train accuracy :  37.905  Validation accuracy :  36.41\n",
      "Epoch 396/500 ...........\n",
      "Loss : 6.73477577729  Train accuracy :  37.9075  Validation accuracy :  36.43\n",
      "Epoch 397/500 ...........\n",
      "Loss : 6.734646818  Train accuracy :  37.93  Validation accuracy :  36.42\n",
      "Epoch 398/500 ...........\n",
      "Loss : 6.73452696273  Train accuracy :  37.9325  Validation accuracy :  36.4\n",
      "Epoch 399/500 ...........\n",
      "Loss : 6.73438811638  Train accuracy :  37.9425  Validation accuracy :  36.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500 ...........\n",
      "Loss : 6.73425857587  Train accuracy :  37.965  Validation accuracy :  36.45\n",
      "Epoch 401/500 ...........\n",
      "Loss : 6.7341301698  Train accuracy :  37.9725  Validation accuracy :  36.44\n",
      "Epoch 402/500 ...........\n",
      "Loss : 6.73400211742  Train accuracy :  37.97  Validation accuracy :  36.44\n",
      "Epoch 403/500 ...........\n",
      "Loss : 6.73387295723  Train accuracy :  37.9675  Validation accuracy :  36.45\n",
      "Epoch 404/500 ...........\n",
      "Loss : 6.73374756348  Train accuracy :  37.9725  Validation accuracy :  36.49\n",
      "Epoch 405/500 ...........\n",
      "Loss : 6.7336216534  Train accuracy :  37.9825  Validation accuracy :  36.49\n",
      "Epoch 406/500 ...........\n",
      "Loss : 6.73349531961  Train accuracy :  38.01  Validation accuracy :  36.49\n",
      "Epoch 407/500 ...........\n",
      "Loss : 6.73336722895  Train accuracy :  38.015  Validation accuracy :  36.52\n",
      "Epoch 408/500 ...........\n",
      "Loss : 6.73324539361  Train accuracy :  38.02  Validation accuracy :  36.54\n",
      "Epoch 409/500 ...........\n",
      "Loss : 6.73311830916  Train accuracy :  38.0475  Validation accuracy :  36.53\n",
      "Epoch 410/500 ...........\n",
      "Loss : 6.73300036823  Train accuracy :  38.0525  Validation accuracy :  36.49\n",
      "Epoch 411/500 ...........\n",
      "Loss : 6.73287005017  Train accuracy :  38.0525  Validation accuracy :  36.49\n",
      "Epoch 412/500 ...........\n",
      "Loss : 6.73275117737  Train accuracy :  38.085  Validation accuracy :  36.52\n",
      "Epoch 413/500 ...........\n",
      "Loss : 6.73262601918  Train accuracy :  38.08  Validation accuracy :  36.48\n",
      "Epoch 414/500 ...........\n",
      "Loss : 6.73250100231  Train accuracy :  38.0825  Validation accuracy :  36.57\n",
      "Epoch 415/500 ...........\n",
      "Loss : 6.7323812885  Train accuracy :  38.1075  Validation accuracy :  36.54\n",
      "Epoch 416/500 ...........\n",
      "Loss : 6.73225582323  Train accuracy :  38.0975  Validation accuracy :  36.55\n",
      "Epoch 417/500 ...........\n",
      "Loss : 6.73214480517  Train accuracy :  38.1  Validation accuracy :  36.56\n",
      "Epoch 418/500 ...........\n",
      "Loss : 6.73201690349  Train accuracy :  38.1075  Validation accuracy :  36.54\n",
      "Epoch 419/500 ...........\n",
      "Loss : 6.73189237528  Train accuracy :  38.105  Validation accuracy :  36.55\n",
      "Epoch 420/500 ...........\n",
      "Loss : 6.73177153124  Train accuracy :  38.145  Validation accuracy :  36.54\n",
      "Epoch 421/500 ...........\n",
      "Loss : 6.73165460972  Train accuracy :  38.1325  Validation accuracy :  36.58\n",
      "Epoch 422/500 ...........\n",
      "Loss : 6.73153382133  Train accuracy :  38.1325  Validation accuracy :  36.56\n",
      "Epoch 423/500 ...........\n",
      "Loss : 6.73141402896  Train accuracy :  38.1575  Validation accuracy :  36.55\n",
      "Epoch 424/500 ...........\n",
      "Loss : 6.73129424964  Train accuracy :  38.1425  Validation accuracy :  36.56\n",
      "Epoch 425/500 ...........\n",
      "Loss : 6.73117638519  Train accuracy :  38.1625  Validation accuracy :  36.56\n",
      "Epoch 426/500 ...........\n",
      "Loss : 6.73106075114  Train accuracy :  38.165  Validation accuracy :  36.58\n",
      "Epoch 427/500 ...........\n",
      "Loss : 6.73094652474  Train accuracy :  38.175  Validation accuracy :  36.57\n",
      "Epoch 428/500 ...........\n",
      "Loss : 6.73082405662  Train accuracy :  38.205  Validation accuracy :  36.58\n",
      "Epoch 429/500 ...........\n",
      "Loss : 6.7307173281  Train accuracy :  38.1925  Validation accuracy :  36.59\n",
      "Epoch 430/500 ...........\n",
      "Loss : 6.730589075  Train accuracy :  38.2  Validation accuracy :  36.59\n",
      "Epoch 431/500 ...........\n",
      "Loss : 6.73047373765  Train accuracy :  38.22  Validation accuracy :  36.57\n",
      "Epoch 432/500 ...........\n",
      "Loss : 6.73035751875  Train accuracy :  38.22  Validation accuracy :  36.59\n",
      "Epoch 433/500 ...........\n",
      "Loss : 6.73024500985  Train accuracy :  38.25  Validation accuracy :  36.57\n",
      "Epoch 434/500 ...........\n",
      "Loss : 6.73013465009  Train accuracy :  38.2675  Validation accuracy :  36.6\n",
      "Epoch 435/500 ...........\n",
      "Loss : 6.73001404829  Train accuracy :  38.2675  Validation accuracy :  36.63\n",
      "Epoch 436/500 ...........\n",
      "Loss : 6.72989888501  Train accuracy :  38.2675  Validation accuracy :  36.62\n",
      "Epoch 437/500 ...........\n",
      "Loss : 6.7297851373  Train accuracy :  38.3025  Validation accuracy :  36.6\n",
      "Epoch 438/500 ...........\n",
      "Loss : 6.72967738161  Train accuracy :  38.3125  Validation accuracy :  36.59\n",
      "Epoch 439/500 ...........\n",
      "Loss : 6.72956191289  Train accuracy :  38.3  Validation accuracy :  36.6\n",
      "Epoch 440/500 ...........\n",
      "Loss : 6.72944869885  Train accuracy :  38.32  Validation accuracy :  36.6\n",
      "Epoch 441/500 ...........\n",
      "Loss : 6.72934028108  Train accuracy :  38.34  Validation accuracy :  36.63\n",
      "Epoch 442/500 ...........\n",
      "Loss : 6.72922150941  Train accuracy :  38.345  Validation accuracy :  36.64\n",
      "Epoch 443/500 ...........\n",
      "Loss : 6.72911687189  Train accuracy :  38.3625  Validation accuracy :  36.63\n",
      "Epoch 444/500 ...........\n",
      "Loss : 6.72900541216  Train accuracy :  38.355  Validation accuracy :  36.63\n",
      "Epoch 445/500 ...........\n",
      "Loss : 6.72889201311  Train accuracy :  38.405  Validation accuracy :  36.65\n",
      "Epoch 446/500 ...........\n",
      "Loss : 6.72877668503  Train accuracy :  38.395  Validation accuracy :  36.67\n",
      "Epoch 447/500 ...........\n",
      "Loss : 6.7286671595  Train accuracy :  38.395  Validation accuracy :  36.66\n",
      "Epoch 448/500 ...........\n",
      "Loss : 6.72855811466  Train accuracy :  38.42  Validation accuracy :  36.64\n",
      "Epoch 449/500 ...........\n",
      "Loss : 6.72844899037  Train accuracy :  38.4325  Validation accuracy :  36.68\n",
      "Epoch 450/500 ...........\n",
      "Loss : 6.72833786859  Train accuracy :  38.4375  Validation accuracy :  36.66\n",
      "Epoch 451/500 ...........\n",
      "Loss : 6.72822958623  Train accuracy :  38.45  Validation accuracy :  36.59\n",
      "Epoch 452/500 ...........\n",
      "Loss : 6.72812035755  Train accuracy :  38.425  Validation accuracy :  36.64\n",
      "Epoch 453/500 ...........\n",
      "Loss : 6.72802686023  Train accuracy :  38.4525  Validation accuracy :  36.68\n",
      "Epoch 454/500 ...........\n",
      "Loss : 6.72791466591  Train accuracy :  38.46  Validation accuracy :  36.64\n",
      "Epoch 455/500 ...........\n",
      "Loss : 6.72780141557  Train accuracy :  38.465  Validation accuracy :  36.64\n",
      "Epoch 456/500 ...........\n",
      "Loss : 6.72768827672  Train accuracy :  38.46  Validation accuracy :  36.64\n",
      "Epoch 457/500 ...........\n",
      "Loss : 6.72758927511  Train accuracy :  38.4825  Validation accuracy :  36.65\n",
      "Epoch 458/500 ...........\n",
      "Loss : 6.72747618656  Train accuracy :  38.4925  Validation accuracy :  36.66\n",
      "Epoch 459/500 ...........\n",
      "Loss : 6.7273698888  Train accuracy :  38.4875  Validation accuracy :  36.65\n",
      "Epoch 460/500 ...........\n",
      "Loss : 6.72726263714  Train accuracy :  38.49  Validation accuracy :  36.64\n",
      "Epoch 461/500 ...........\n",
      "Loss : 6.7271557548  Train accuracy :  38.5225  Validation accuracy :  36.62\n",
      "Epoch 462/500 ...........\n",
      "Loss : 6.7270513329  Train accuracy :  38.5175  Validation accuracy :  36.62\n",
      "Epoch 463/500 ...........\n",
      "Loss : 6.72694726256  Train accuracy :  38.5225  Validation accuracy :  36.67\n",
      "Epoch 464/500 ...........\n",
      "Loss : 6.72684005613  Train accuracy :  38.52  Validation accuracy :  36.65\n",
      "Epoch 465/500 ...........\n",
      "Loss : 6.7267371006  Train accuracy :  38.5425  Validation accuracy :  36.63\n",
      "Epoch 466/500 ...........\n",
      "Loss : 6.72663186483  Train accuracy :  38.5275  Validation accuracy :  36.65\n",
      "Epoch 467/500 ...........\n",
      "Loss : 6.72653448947  Train accuracy :  38.5475  Validation accuracy :  36.62\n",
      "Epoch 468/500 ...........\n",
      "Loss : 6.72642689658  Train accuracy :  38.565  Validation accuracy :  36.68\n",
      "Epoch 469/500 ...........\n",
      "Loss : 6.72632389299  Train accuracy :  38.56  Validation accuracy :  36.64\n",
      "Epoch 470/500 ...........\n",
      "Loss : 6.72621938093  Train accuracy :  38.58  Validation accuracy :  36.67\n",
      "Epoch 471/500 ...........\n",
      "Loss : 6.72612306944  Train accuracy :  38.5975  Validation accuracy :  36.68\n",
      "Epoch 472/500 ...........\n",
      "Loss : 6.72601706371  Train accuracy :  38.6125  Validation accuracy :  36.68\n",
      "Epoch 473/500 ...........\n",
      "Loss : 6.72591233773  Train accuracy :  38.63  Validation accuracy :  36.67\n",
      "Epoch 474/500 ...........\n",
      "Loss : 6.7258086561  Train accuracy :  38.63  Validation accuracy :  36.68\n",
      "Epoch 475/500 ...........\n",
      "Loss : 6.72571073476  Train accuracy :  38.65  Validation accuracy :  36.7\n",
      "Epoch 476/500 ...........\n",
      "Loss : 6.72561049049  Train accuracy :  38.665  Validation accuracy :  36.69\n",
      "Epoch 477/500 ...........\n",
      "Loss : 6.72550635438  Train accuracy :  38.665  Validation accuracy :  36.71\n",
      "Epoch 478/500 ...........\n",
      "Loss : 6.72540486918  Train accuracy :  38.6775  Validation accuracy :  36.68\n",
      "Epoch 479/500 ...........\n",
      "Loss : 6.72530496238  Train accuracy :  38.68  Validation accuracy :  36.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/500 ...........\n",
      "Loss : 6.72520587607  Train accuracy :  38.7025  Validation accuracy :  36.7\n",
      "Epoch 481/500 ...........\n",
      "Loss : 6.7251226651  Train accuracy :  38.6925  Validation accuracy :  36.72\n",
      "Epoch 482/500 ...........\n",
      "Loss : 6.7250125444  Train accuracy :  38.7075  Validation accuracy :  36.74\n",
      "Epoch 483/500 ...........\n",
      "Loss : 6.72491123285  Train accuracy :  38.7325  Validation accuracy :  36.74\n",
      "Epoch 484/500 ...........\n",
      "Loss : 6.72480933524  Train accuracy :  38.73  Validation accuracy :  36.81\n",
      "Epoch 485/500 ...........\n",
      "Loss : 6.72470999594  Train accuracy :  38.725  Validation accuracy :  36.83\n",
      "Epoch 486/500 ...........\n",
      "Loss : 6.72461121734  Train accuracy :  38.7375  Validation accuracy :  36.83\n",
      "Epoch 487/500 ...........\n",
      "Loss : 6.72451725467  Train accuracy :  38.73  Validation accuracy :  36.74\n",
      "Epoch 488/500 ...........\n",
      "Loss : 6.72441993992  Train accuracy :  38.74  Validation accuracy :  36.81\n",
      "Epoch 489/500 ...........\n",
      "Loss : 6.72431783627  Train accuracy :  38.745  Validation accuracy :  36.81\n",
      "Epoch 490/500 ...........\n",
      "Loss : 6.72422025615  Train accuracy :  38.755  Validation accuracy :  36.84\n",
      "Epoch 491/500 ...........\n",
      "Loss : 6.72412910569  Train accuracy :  38.775  Validation accuracy :  36.81\n",
      "Epoch 492/500 ...........\n",
      "Loss : 6.72403712453  Train accuracy :  38.7725  Validation accuracy :  36.89\n",
      "Epoch 493/500 ...........\n",
      "Loss : 6.72394558907  Train accuracy :  38.79  Validation accuracy :  36.93\n",
      "Epoch 494/500 ...........\n",
      "Loss : 6.72383609903  Train accuracy :  38.795  Validation accuracy :  36.88\n",
      "Epoch 495/500 ...........\n",
      "Loss : 6.72373960097  Train accuracy :  38.805  Validation accuracy :  36.9\n",
      "Epoch 496/500 ...........\n",
      "Loss : 6.72364358541  Train accuracy :  38.8375  Validation accuracy :  36.88\n",
      "Epoch 497/500 ...........\n",
      "Loss : 6.72354803826  Train accuracy :  38.8275  Validation accuracy :  36.86\n",
      "Epoch 498/500 ...........\n",
      "Loss : 6.72345755878  Train accuracy :  38.84  Validation accuracy :  36.88\n",
      "Epoch 499/500 ...........\n",
      "Loss : 6.72335996353  Train accuracy :  38.8375  Validation accuracy :  36.91\n"
     ]
    }
   ],
   "source": [
    "# Now let's train a very simple baseline classification model - one-vs-all multiclass logistic regression\n",
    "num_classes = len(class_names)\n",
    "\n",
    "train_data = np.array(train_data, dtype=float)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(\"Data shape : \", train_data.shape)\n",
    "print(\"Labels shape : \", train_labels.shape)\n",
    "\n",
    "num_features = train_data.shape[1]\n",
    "num_samples = train_data.shape[0]\n",
    "num_train_samples = 40000\n",
    "\n",
    "p = np.random.permutation(num_samples)\n",
    "x_train = train_data[p[0:num_train_samples], :]\n",
    "y_train = train_labels[p[0:num_train_samples]]\n",
    "\n",
    "x_val = train_data[p[num_train_samples:], :]\n",
    "val_labels = train_labels[p[num_train_samples:]]\n",
    "train_labels = y_train\n",
    "\n",
    "x_train, m_train, v_train = preprocess_data(x_train, np.array([]), np.array([]))\n",
    "y_train = preprocess_labels(y_train, num_classes)\n",
    "\n",
    "x_val, _, _ = preprocess_data(x_val, m_train, v_train)\n",
    "\n",
    "theta = np.random.randn(num_features, num_classes)\n",
    "\n",
    "num_batches = num_train_samples // batch_size\n",
    "\n",
    "y_pred = forward(theta, x_train)\n",
    "loss_val = loss(y_train, y_pred)\n",
    "print(\"Initial loss :\", loss_val)\n",
    "\n",
    "for i in range(0, num_epochs):\n",
    "    p = np.random.permutation(num_train_samples)\n",
    "    print('Epoch %d/%d ' % (i, num_epochs), end='.')\n",
    "    for batch_no in range(0, num_batches):\n",
    "        if np.mod(batch_no, num_batches // 10) == 0:\n",
    "            print('.', end='')\n",
    "            sys.stdout.flush()\n",
    "        x_train_batch = x_train[p[batch_no * batch_size : (batch_no+1) * batch_size], :]\n",
    "        y_train_batch = y_train[p[batch_no * batch_size: (batch_no + 1) * batch_size]]\n",
    "        d_theta = backward(x_train_batch, y_train_batch, theta)\n",
    "        theta = theta - alpha*d_theta\n",
    "\n",
    "    # if np.mod(i, num_epochs // 10) == 0:\n",
    "    pred_train_probs = forward(theta, x_train)\n",
    "    pred_train_labels = np.argmax(pred_train_probs, axis=1)\n",
    "    loss_val = loss(y_train, pred_train_probs)\n",
    "\n",
    "    pred_val_labels = np.argmax(forward(theta, x_val), axis=1)\n",
    "    print(\"\\nLoss :\", loss_val,\n",
    "          \" Train accuracy : \", (1-np.mean(pred_train_labels != train_labels))*100,\n",
    "          \" Validation accuracy : \", (1 - np.mean(pred_val_labels != val_labels)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим точность на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy :  36.75\n"
     ]
    }
   ],
   "source": [
    "test_samples = pickle.load(open(data_dir_name + \"/test_batch\", \"rb\"), encoding=\"bytes\")\n",
    "test_labels = test_samples[b\"labels\"]\n",
    "test_data = test_samples[b\"data\"]\n",
    "x_test, _, _ = preprocess_data(test_data, m_train, v_train)\n",
    "predictions = np.argmax(forward(theta, x_test), axis=1)\n",
    "print(\"\\nTest accuracy : \", 100*np.mean(predictions == test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
