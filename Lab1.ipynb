{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import pickle\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# GLOBAL PARAMETERS\n",
    "# Data\n",
    "cifar_file_name = \"cifar-10-python.tar.gz\"\n",
    "url = 'https://www.cs.toronto.edu/~kriz/'\n",
    "data_root = '.' # Change me to store data elsewhere\n",
    "cifar_dir_name = \"cifar-10-batches-py\"  # where cifar data is stored locally\n",
    "# Learning\n",
    "alpha = 0.5  # learning rate\n",
    "num_epochs = 500  # number of learning epochs \n",
    "batch_size = 1000  # mini-batch size for gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функции для загрузки данных с удаленного сервера и разархивации их в локальный каталог."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File  .\\cifar-10-python.tar.gz  size :  170498071  bytes.\n"
     ]
    }
   ],
   "source": [
    "def maybe_download():\n",
    "    \"\"\"Download the file if it does not exist.\"\"\"\n",
    "\n",
    "    dest_file_name = os.path.join(data_root, cifar_file_name)\n",
    "\n",
    "    if not os.path.exists(dest_file_name):\n",
    "        urlretrieve(url + cifar_file_name, dest_file_name)\n",
    "\n",
    "    statinfo = os.stat(dest_file_name)\n",
    "    print(\"File \", dest_file_name, \" size : \", statinfo.st_size, \" bytes.\")\n",
    "\n",
    "    return dest_file_name\n",
    "\n",
    "\n",
    "def maybe_extract(file_name):\n",
    "    \"\"\"Extract compressed file if is was not uncomressed before.\"\"\"\n",
    "\n",
    "    tar = tarfile.open(file_name)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "\n",
    "    dest_dir_name = os.path.join(data_root, cifar_dir_name)\n",
    "    if not os.path.exists(dest_dir_name):\n",
    "        raise Exception(\"No data directory. Check that archive with data exists, not corrupted and contains \",\n",
    "                        cifar_dir_name, \" inside.\")\n",
    "\n",
    "    return dest_dir_name\n",
    "\n",
    "\n",
    "data_file_name = maybe_download()\n",
    "data_dir_name = maybe_extract(data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных.\n",
    "\n",
    "После разархивации получим набор двоичных фалов, в которых хранятся данные CIFAR. \n",
    "\n",
    "Тренировочная выборка разбита на 5 файлов (data_batch_1, ..., data_batch_5). Прочтем все эти файлы и объединим данные из них в один массив. Затем загрузим тестовую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  .\\cifar-10-batches-py/data_batch_1 ...\n",
      "Done.\n",
      "Loading  .\\cifar-10-batches-py/data_batch_2 ...\n",
      "Done.\n",
      "Loading  .\\cifar-10-batches-py/data_batch_3 ...\n",
      "Done.\n",
      "Loading  .\\cifar-10-batches-py/data_batch_4 ...\n",
      "Done.\n",
      "Loading  .\\cifar-10-batches-py/data_batch_5 ...\n",
      "Done.\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# load train and test data\n",
    "train_batches = [\"data_batch_1\",\n",
    "                 \"data_batch_2\",\n",
    "                 \"data_batch_3\",\n",
    "                 \"data_batch_4\",\n",
    "                 \"data_batch_5\",\n",
    "                ]\n",
    "\n",
    "\n",
    "train_labels = []\n",
    "train_data = []\n",
    "for train_batch in train_batches:\n",
    "    path_to_batch = data_dir_name + \"/\" + train_batch\n",
    "    print(\"Loading \", path_to_batch, \"...\")\n",
    "    batch = pickle.load(open(path_to_batch, \"rb\"), encoding=\"bytes\")\n",
    "    # batch is a dictionary, dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
    "    # let's store data and labels for all batches in a separate arrays\n",
    "    train_labels.extend(batch[b\"labels\"])\n",
    "    train_data.extend(batch[b\"data\"])\n",
    "    print(\"Done.\")\n",
    "    \n",
    "# also load titles for labels\n",
    "raw = pickle.load(open(data_dir_name + \"/batches.meta\", \"rb\"))\n",
    "class_names = [x for x in raw[\"label_names\"]]\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f3c34c42e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's have a look at a sample image\n",
    "sample_no = 0\n",
    "sample_data = train_data[sample_no]\n",
    "\n",
    "sample_image = np.reshape(sample_data, [3, 32, 32])\n",
    "sample_image = np.swapaxes(sample_image, 0, 2)\n",
    "sample_image = np.transpose(sample_image, [1, 0, 2])\n",
    "\n",
    "matplotlib.pyplot.imshow(sample_image)\n",
    "print(class_names[train_labels[sample_no]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, m, v):\n",
    "    if not m.any():\n",
    "        m = np.mean(X, axis=0)\n",
    "    if not v.any():\n",
    "        v = np.var(X, axis=0)\n",
    "    X = (X - m) / v\n",
    "    return X, m, v\n",
    "\n",
    "\n",
    "def preprocess_labels(y, num_classes):\n",
    "    y_gt = np.zeros((len(y), num_classes))\n",
    "    for i in range(0, len(y)):\n",
    "        y_gt[i, y[i]] = 1\n",
    "    return y_gt\n",
    "\n",
    "\n",
    "def h(theta, X):\n",
    "    return 1.0 / (1 + np.exp(-np.dot(X, theta)))\n",
    "\n",
    "\n",
    "def loss(y_gt, y_pred):\n",
    "    cross_entropy_error = 0.0\n",
    "    for i in range(0, len(y_gt)):\n",
    "        for j in range(0, len(y_gt[i])):\n",
    "            cross_entropy_error -= (y_gt[i][j] * np.log(y_pred[i][j]) + (1 - y_gt[i][j]) * np.log(1 - y_pred[i][j]))\n",
    "    return cross_entropy_error / len(y_gt)\n",
    "\n",
    "\n",
    "def forward(theta_mat, X):\n",
    "    probs = np.array([h(theta_mat[:, i], X) for i in range(0, theta_mat.shape[1])])\n",
    "    return probs.transpose()\n",
    "\n",
    "\n",
    "def derivative(X, y_gt, y_pred):\n",
    "    \"\"\"Derivative of cross-entropy loss over parameters of one logistic classifier.\"\"\"\n",
    "    return np.dot(y_pred - y_gt, X) / len(y_gt)\n",
    "\n",
    "def backward(X, y_gt, theta):\n",
    "    num_features = X.shape[1]\n",
    "    num_classes = y_gt.shape[1]\n",
    "    d_theta = np.zeros([num_features, num_classes])\n",
    "    y_pred = forward(theta, X)\n",
    "    for class_no in range(0, num_classes):\n",
    "        d_theta[:, class_no] = derivative(X, y_gt[:, class_no], y_pred[:, class_no])\n",
    "    return d_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape :  (50000, 3072)\n",
      "Labels shape :  (50000,)\n",
      "Initial loss : 7.75398370431\n",
      "Epoch 0/10 ...........\n",
      "Loss : 7.44106669561  Train accuracy :  12.9125  Validation accuracy :  12.92\n",
      "Epoch 1/10 ...........\n",
      "Loss : 7.31513770111  Train accuracy :  14.6125  Validation accuracy :  14.64\n",
      "Epoch 2/10 ...........\n",
      "Loss : 7.24462578843  Train accuracy :  16.06  Validation accuracy :  15.78\n",
      "Epoch 3/10 ...........\n",
      "Loss : 7.19602106057  Train accuracy :  17.09  Validation accuracy :  16.62\n",
      "Epoch 4/10 ...........\n",
      "Loss : 7.15915454413  Train accuracy :  17.965  Validation accuracy :  17.33\n",
      "Epoch 5/10 ...........\n",
      "Loss : 7.12979996478  Train accuracy :  18.71  Validation accuracy :  18.24\n",
      "Epoch 6/10 ...........\n",
      "Loss : 7.10557221556  Train accuracy :  19.43  Validation accuracy :  19.15\n",
      "Epoch 7/10 ...........\n",
      "Loss : 7.0851491883  Train accuracy :  19.99  Validation accuracy :  19.74\n",
      "Epoch 8/10 ...........\n",
      "Loss : 7.0676505883  Train accuracy :  20.6  Validation accuracy :  20.24\n",
      "Epoch 9/10 ...........\n",
      "Loss : 7.05244341923  Train accuracy :  21.095  Validation accuracy :  20.72\n"
     ]
    }
   ],
   "source": [
    "# Now let's train a very simple baseline classification model - one-vs-all multiclass logistic regression\n",
    "num_classes = len(class_names)\n",
    "\n",
    "train_data = np.array(train_data, dtype=float)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(\"Data shape : \", train_data.shape)\n",
    "print(\"Labels shape : \", train_labels.shape)\n",
    "\n",
    "num_features = train_data.shape[1]\n",
    "num_samples = train_data.shape[0]\n",
    "num_train_samples = 40000\n",
    "\n",
    "p = np.random.permutation(num_samples)\n",
    "x_train = train_data[p[0:num_train_samples], :]\n",
    "y_train = train_labels[p[0:num_train_samples]]\n",
    "\n",
    "x_val = train_data[p[num_train_samples:], :]\n",
    "val_labels = train_labels[p[num_train_samples:]]\n",
    "train_labels = y_train\n",
    "\n",
    "x_train, m_train, v_train = preprocess_data(x_train, np.array([]), np.array([]))\n",
    "y_train = preprocess_labels(y_train, num_classes)\n",
    "\n",
    "x_val, _, _ = preprocess_data(x_val, m_train, v_train)\n",
    "\n",
    "theta = np.random.randn(num_features, num_classes)\n",
    "\n",
    "num_batches = num_train_samples // batch_size\n",
    "\n",
    "y_pred = forward(theta, x_train)\n",
    "loss_val = loss(y_train, y_pred)\n",
    "print(\"Initial loss :\", loss_val)\n",
    "\n",
    "for i in range(0, num_epochs):\n",
    "    p = np.random.permutation(num_train_samples)\n",
    "    print('Epoch %d/%d ' % (i, num_epochs), end='.')\n",
    "    for batch_no in range(0, num_batches):\n",
    "        if np.mod(batch_no, num_batches // 10) == 0:\n",
    "            print('.', end='')\n",
    "            sys.stdout.flush()\n",
    "        x_train_batch = x_train[p[batch_no * batch_size : (batch_no+1) * batch_size], :]\n",
    "        y_train_batch = y_train[p[batch_no * batch_size: (batch_no + 1) * batch_size]]\n",
    "        d_theta = backward(x_train_batch, y_train_batch, theta)\n",
    "        theta = theta - alpha*d_theta\n",
    "\n",
    "    # if np.mod(i, num_epochs // 10) == 0:\n",
    "    pred_train_probs = forward(theta, x_train)\n",
    "    pred_train_labels = np.argmax(pred_train_probs, axis=1)\n",
    "    loss_val = loss(y_train, pred_train_probs)\n",
    "\n",
    "    pred_val_labels = np.argmax(forward(theta, x_val), axis=1)\n",
    "    print(\"\\nLoss :\", loss_val,\n",
    "          \" Train accuracy : \", (1-np.mean(pred_train_labels != train_labels))*100,\n",
    "          \" Validation accuracy : \", (1 - np.mean(pred_val_labels != val_labels)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим точность на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_samples = pickle.load(open(data_dir_name + \"/test_batch\", \"rb\"), encoding=\"bytes\")\n",
    "test_labels = test_samples[b\"labels\"]\n",
    "test_data = test_samples[b\"data\"]\n",
    "x_test, _, _ = preprocess_data(test_data, m_train, v_train)\n",
    "predictions = np.argmax(forward(theta, x_test), axis=1)\n",
    "print(\"\\nTest accuracy : \", np.mean(predictions != test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
